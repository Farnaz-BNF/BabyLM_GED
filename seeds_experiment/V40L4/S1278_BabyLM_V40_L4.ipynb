{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "K4K9n93EGR2l"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import transformers\n",
        "import pandas as pd\n",
        "from transformers.trainer import *\n",
        "from transformers import RobertaConfig\n",
        "from transformers import RobertaForMaskedLM\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from transformers import RobertaTokenizerFast\n",
        "from torch.utils.data import SequentialSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer, RobertaModel\n",
        "from transformers import DataCollatorForLanguageModeling"
      ],
      "metadata": {
        "id": "ajNr4mE7_n5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89NPyPRbUlPx",
        "outputId": "7edc8cc7-6f91-4616-d3e9-ca54caa3c82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278\""
      ],
      "metadata": {
        "id": "tyeTVVi-WP2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_directory_path):\n",
        "  all_data = []\n",
        "  total_sentence = 0\n",
        "  for filename in os.listdir(data_directory_path):\n",
        "    file_path = os.path.join(data_directory_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "      print(f'Reading file: {filename}')\n",
        "      with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "          total_sentence+=1\n",
        "          all_data.append(line.strip())\n",
        "  print(f\"total sentece in directory: {total_sentence}\")\n",
        "  return all_data"
      ],
      "metadata": {
        "id": "ZtfvzGt5EEVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory_path = '/content/drive/MyDrive/VU Thesis/Code/Data/babylm_10M'\n",
        "sequences = load_data(train_directory_path)\n",
        "print('='*50)\n",
        "\n",
        "dev_directory_path = '/content/drive/MyDrive/VU Thesis/Code/Data/babylm_dev'\n",
        "devset = load_data(dev_directory_path)\n",
        "print('='*50)\n",
        "\n",
        "test_directory_path = '/content/drive/MyDrive/VU Thesis/Code/Data/babylm_test'\n",
        "test_data = load_data(test_directory_path)\n",
        "print('='*50)\n",
        "\n",
        "print(len(sequences))\n",
        "print(len(devset))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "OAYA9cYv_pM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a51ac8c-829d-4f74-942f-17dfcaff872f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file: wikipedia.train\n",
            "Reading file: gutenberg.train\n",
            "Reading file: open_subtitles.train\n",
            "Reading file: simple_wikipedia.train\n",
            "Reading file: qed.train\n",
            "Reading file: aochildes.train\n",
            "Reading file: bnc_spoken.train\n",
            "Reading file: switchboard.train\n",
            "Reading file: children_stories.train\n",
            "Reading file: cbt.train\n",
            "total sentece in directory: 1058740\n",
            "==================================================\n",
            "Reading file: gutenberg.dev\n",
            "Reading file: bnc_spoken.dev\n",
            "Reading file: open_subtitles.dev\n",
            "Reading file: children_stories.dev\n",
            "Reading file: cbt.dev\n",
            "Reading file: qed.dev\n",
            "Reading file: aochildes.dev\n",
            "Reading file: wikipedia.dev\n",
            "Reading file: simple_wikipedia.dev\n",
            "Reading file: switchboard.dev\n",
            "total sentece in directory: 1026747\n",
            "==================================================\n",
            "Reading file: cbt.test\n",
            "Reading file: children_stories.test\n",
            "Reading file: aochildes.test\n",
            "Reading file: bnc_spoken.test\n",
            "Reading file: gutenberg.test\n",
            "Reading file: simple_wikipedia.test\n",
            "Reading file: open_subtitles.test\n",
            "Reading file: switchboard.test\n",
            "Reading file: wikipedia.test\n",
            "Reading file: qed.test\n",
            "total sentece in directory: 1054646\n",
            "==================================================\n",
            "1058740\n",
            "1026747\n",
            "1054646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_folder = '/content/drive/MyDrive/VU Thesis/Code/baby_models/tokenizer_V40_folder'\n",
        "\n",
        "# if not os.path.exists(tokenizer_folder):\n",
        "  # os.mkdir(tokenizer_folder)"
      ],
      "metadata": {
        "id": "MzNl_-6P_qif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tokenizer(sequence_data, vocab_size, tokenizer_folder):\n",
        "  # Initialize tokenizer\n",
        "  tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "  tokenizer.train_from_iterator(sequences,\n",
        "                                vocab_size=vocab_size,\n",
        "                                min_frequency=2,\n",
        "                                show_progress=True,\n",
        "                                special_tokens=[\n",
        "                                    \"<s>\",\n",
        "                                    \"<pad>\",\n",
        "                                    \"</s>\",\n",
        "                                    \"<unk>\",\n",
        "                                    \"<mask>\"]\n",
        "                                )\n",
        "  # Save tokenizer\n",
        "  tokenizer.save_model(tokenizer_folder)\n",
        "\n",
        "if not os.path.exists(tokenizer_folder):\n",
        "  os.mkdir(tokenizer_folder)\n",
        "  train_tokenizer(sequences, 20_480, tokenizer_folder)"
      ],
      "metadata": {
        "id": "2A_EdNBWGjNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create CustomDataset class\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.examples = []\n",
        "    self.mask = []\n",
        "    max_length = 512\n",
        "    for example in data:\n",
        "      x=tokenizer.encode_plus(example, max_length = max_length, truncation=True, padding=True)\n",
        "      self.examples += [x.input_ids]\n",
        "      self.mask += [x.attention_mask]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return torch.tensor(self.examples[i])"
      ],
      "metadata": {
        "id": "H8-vw_zrqBhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_dataloader(self) -> DataLoader:\n",
        "    \"\"\"\n",
        "    Returns the training :class:`~torch.utils.data.DataLoader`.\n",
        "\n",
        "    Will use no sampler if :obj:`self.train_dataset` does not implement :obj:`__len__`, a random sampler (adapted\n",
        "    to distributed training if necessary) otherwise.\n",
        "\n",
        "    Subclass and override this method if you want to inject some custom behavior.\n",
        "    \"\"\"\n",
        "    if self.train_dataset is None:\n",
        "        raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "\n",
        "    return DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size=self.args.train_batch_size,\n",
        "        sampler=SequentialSampler(self.train_dataset),\n",
        "        collate_fn=self.data_collator,\n",
        "        drop_last=self.args.dataloader_drop_last,\n",
        "        num_workers=self.args.dataloader_num_workers,\n",
        "        shuffle=False\n",
        "    )"
      ],
      "metadata": {
        "id": "XyWPGTuJqIB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_baby_lm(babaylm_config, tokenizer_path, train_data, dev_data, epochs_start, epochs_number, batch_size):\n",
        "    # model = RobertaForMaskedLM(config=babaylm_config)\n",
        "    # print('Model parameters: ',model.num_parameters())\n",
        "    max_length = 512\n",
        "    tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_path, max_len=max_length)\n",
        "\n",
        "    # Define data collator\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
        "    Trainer.get_train_dataloader = get_train_dataloader\n",
        "\n",
        "    # batch_size = 16\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f'{model_path}/run_model_s1278_folder',\n",
        "        overwrite_output_dir=True,\n",
        "        eval_strategy = 'epoch',\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=1e-4,\n",
        "        weight_decay=0.01,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        save_strategy=\"epoch\",\n",
        "        seed=1278,\n",
        "        save_total_limit=1,\n",
        "        max_steps=int(len(train_dataset)/ batch_size)\n",
        "    )\n",
        "\n",
        "    model = RobertaForMaskedLM(config=babaylm_config)\n",
        "    print('Model parameters: ',model.num_parameters())\n",
        "\n",
        "    for i in range(epochs_start, epochs_start + epochs_number):\n",
        "\n",
        "        # if os.path.exists(f'{model_path}/model_s1278_e{i}_v40_l4'):\n",
        "        #     model = RobertaForMaskedLM.from_pretrained(f'{model_path}/model_s1278_e{i}_v40_l4')\n",
        "        #     print(f\"pretrained model load (from Epoch {i})...\")\n",
        "\n",
        "        # else:\n",
        "        #     print(\"No checkpoint... Create New Model\")\n",
        "        #     model = RobertaForMaskedLM(config=babaylm_config)\n",
        "        #     print('Model parameters: ',model.num_parameters())\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            data_collator=data_collator,\n",
        "            train_dataset=train_data,#train_dataset,\n",
        "            eval_dataset=dev_data,#eval_dataset,\n",
        "            tokenizer=tokenizer)\n",
        "\n",
        "        trainer.train()\n",
        "        trainer.save_model(f'{model_path}/model_s1278_e{i+1}_v40_l4')"
      ],
      "metadata": {
        "id": "clxn9BJZpKoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "max_length = 512\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=max_length)\n",
        "\n",
        "train_custom_data_path =  \"/content/drive/MyDrive/VU Thesis/Code/baby_models/train_V40.pkl\"\n",
        "dev_custom_data_path = \"/content/drive/MyDrive/VU Thesis/Code/baby_models/dev_V40.pkl\"\n",
        "\n",
        "if os.path.isfile(train_custom_data_path):\n",
        "  with open(train_custom_data_path, 'rb') as file:\n",
        "    train_dataset = pickle.load(file)\n",
        "else:\n",
        "  train_dataset = CustomDataset(sequences, tokenizer)\n",
        "  with open(train_custom_data_path, 'wb') as file:\n",
        "    pickle.dump(train_dataset, file)\n",
        "\n",
        "\n",
        "if os.path.isfile(dev_custom_data_path):\n",
        "  with open(dev_custom_data_path, 'rb') as file:\n",
        "    eval_dataset = pickle.load(file)\n",
        "else:\n",
        "  eval_dataset = CustomDataset(devset, tokenizer)\n",
        "  with open(dev_custom_data_path, 'wb') as file:\n",
        "    pickle.dump(eval_dataset, file)"
      ],
      "metadata": {
        "id": "-KFanF-9wUr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Epochs 1-5\n",
        "config = RobertaConfig(\n",
        "    vocab_size=40960,\n",
        "    num_hidden_layers=4,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=8,\n",
        "    type_vocab_size=1,\n",
        "    intermediate_size=3072,\n",
        "    layer_norm_eps = 1e-05,\n",
        "    hidden_size=256,\n",
        "    initializer_range=0.02,\n",
        "    classifier_dropout = None,\n",
        "    hidden_act=\"gelu\",\n",
        "    position_embedding_type= \"absolute\",\n",
        "    hidden_dropout_prob= 0.1,\n",
        "    attention_probs_dropout_prob= 0.1,\n",
        ")\n",
        "\n",
        "epochs_start = 0\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "train_baby_lm(config, tokenizer_folder, train_dataset, eval_dataset, epochs_start, epochs, batch_size)"
      ],
      "metadata": {
        "id": "CxgrV8m0sxmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "1e376029-7e3f-48e4-ca9a-b8b0022749cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters:  18086912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-b5e56f42d6da>:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfarnaz-banifatemi-vu\u001b[0m (\u001b[33mfarnaz-banifatemi-vu-vrije-universiteit-amsterdam\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250427_145720-1xu5iy9k</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/farnaz-banifatemi-vu-vrije-universiteit-amsterdam/huggingface/runs/1xu5iy9k' target=\"_blank\">/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/run_model_s1278_folder</a></strong> to <a href='https://wandb.ai/farnaz-banifatemi-vu-vrije-universiteit-amsterdam/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/farnaz-banifatemi-vu-vrije-universiteit-amsterdam/huggingface' target=\"_blank\">https://wandb.ai/farnaz-banifatemi-vu-vrije-universiteit-amsterdam/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/farnaz-banifatemi-vu-vrije-universiteit-amsterdam/huggingface/runs/1xu5iy9k' target=\"_blank\">https://wandb.ai/farnaz-banifatemi-vu-vrije-universiteit-amsterdam/huggingface/runs/1xu5iy9k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33085' max='33085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33085/33085 46:09, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.365800</td>\n",
              "      <td>5.108398</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-b5e56f42d6da>:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33085' max='33085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33085/33085 46:37, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.797600</td>\n",
              "      <td>4.647088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-b5e56f42d6da>:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33085' max='33085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33085/33085 47:09, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.561100</td>\n",
              "      <td>4.456600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-b5e56f42d6da>:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33085' max='33085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33085/33085 47:46, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.472200</td>\n",
              "      <td>4.362375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-b5e56f42d6da>:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33085' max='33085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33085/33085 48:00, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.438000</td>\n",
              "      <td>4.316257</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Epochs 6-10\n",
        "# config = RobertaConfig(\n",
        "#     vocab_size=40960,\n",
        "#     num_hidden_layers=4,\n",
        "#     max_position_embeddings=514,\n",
        "#     num_attention_heads=8,\n",
        "#     type_vocab_size=1,\n",
        "#     intermediate_size=3072,\n",
        "#     layer_norm_eps = 1e-05,\n",
        "#     hidden_size=256,\n",
        "#     initializer_range=0.02,\n",
        "#     classifier_dropout = None,\n",
        "#     hidden_act=\"gelu\",\n",
        "#     position_embedding_type= \"absolute\",\n",
        "#     hidden_dropout_prob= 0.1,\n",
        "#     attention_probs_dropout_prob= 0.1,\n",
        "# )\n",
        "\n",
        "# epochs_start = 5\n",
        "# epochs = 5\n",
        "# batch_size = 32\n",
        "\n",
        "# train_baby_lm(config, tokenizer_folder, train_dataset, eval_dataset, epochs_start, epochs, batch_size)"
      ],
      "metadata": {
        "id": "jGn3Bp_-ywwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLiMP Evaluation for Epoch 5"
      ],
      "metadata": {
        "id": "q0J3NNwdac3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/evaluation-pipeline\" \"/content/\""
      ],
      "metadata": {
        "id": "ZPR0rs54ageo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/lm_eval\" \"/content/\""
      ],
      "metadata": {
        "id": "s18aZ9f0btoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model_folder\n",
        "\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4/config.json\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4/merges.txt\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4/model.safetensors\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4/special_tokens_map.json\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4/tokenizer.json\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4/tokenizer_config.json\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4/training_args.bin\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4/vocab.json\" \"/content/model_folder\""
      ],
      "metadata": {
        "id": "5EdBLVsfbnbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup script { display-mode: \"form\" }\n",
        "#@markdown Run this cell to install the necessary packages (may take a few minutes).\n",
        "%%shell\n",
        "# Remove previous installation if it exists\n",
        "cd /content\n",
        "# mkdir model_folder\n",
        "pip uninstall -y lm-eval\n",
        "# rm -rf evaluation-pipeline/\n",
        "\n",
        "# Install evaluation-pipeline\n",
        "# cp -r /content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/evaluation-pipeline /content/\n",
        "cd evaluation-pipeline/\n",
        "pip install -e \".[colab]\"\n",
        "# Install other necessary packages\n",
        "pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "# Unpack dataset\n",
        "# unzip filter_data.zip"
      ],
      "metadata": {
        "id": "VcKAHtFpbwgb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f25219bd-d1ef-444b-ef75-8152a4e99e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping lm-eval as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mObtaining file:///content/evaluation-pipeline\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate@ git+https://github.com/huggingface/accelerate@main (from lm_eval==0.2.0)\n",
            "  Cloning https://github.com/huggingface/accelerate (to revision main) to /tmp/pip-install-cw5vm9kt/accelerate_94343ee77e074039b20c27a5dd4075f7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-install-cw5vm9kt/accelerate_94343ee77e074039b20c27a5dd4075f7\n",
            "  Resolved https://github.com/huggingface/accelerate to commit 39e2bebb12bc0b9996a523e65e4e201198620f86\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets>=2.0.0 (from lm_eval==0.2.0)\n",
            "  Using cached datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting nltk==3.6 (from lm_eval==0.2.0)\n",
            "  Using cached nltk-3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting openai==0.13.0 (from lm_eval==0.2.0)\n",
            "  Using cached openai-0.13.0.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycountry==20.7.3 (from lm_eval==0.2.0)\n",
            "  Using cached pycountry-20.7.3.tar.gz (10.1 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytablewriter==0.58.0 (from lm_eval==0.2.0)\n",
            "  Using cached pytablewriter-0.58.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting rouge-score==0.0.4 (from lm_eval==0.2.0)\n",
            "  Using cached rouge_score-0.0.4-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting sacrebleu==1.5.0 (from lm_eval==0.2.0)\n",
            "  Using cached sacrebleu-1.5.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.2.0) (1.6.1)\n",
            "Collecting sqlitedict==1.6.0 (from lm_eval==0.2.0)\n",
            "  Using cached sqlitedict-1.6.0.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of lm-eval to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.11.0 (from lm-eval) (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.11.0\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.11.0+cu113 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.11.0+cu113\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command '# Remove previous installation if it exists\ncd /content\n# mkdir model_folder\npip uninstall -y lm-eval\n# rm -rf evaluation-pipeline/\n\n# Install evaluation-pipeline\n# cp -r /content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/evaluation-pipeline /content/\ncd evaluation-pipeline/\npip install -e \".[colab]\"\n# Install other necessary packages\npip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n\n# Unpack dataset\n# unzip filter_data.zip\n' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-655be3614e85>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# Remove previous installation if it exists\\ncd /content\\n# mkdir model_folder\\npip uninstall -y lm-eval\\n# rm -rf evaluation-pipeline/\\n\\n# Install evaluation-pipeline\\n# cp -r /content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/evaluation-pipeline /content/\\ncd evaluation-pipeline/\\npip install -e \".[colab]\"\\n# Install other necessary packages\\npip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\\n\\n# Unpack dataset\\n# unzip filter_data.zip\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '# Remove previous installation if it exists\ncd /content\n# mkdir model_folder\npip uninstall -y lm-eval\n# rm -rf evaluation-pipeline/\n\n# Install evaluation-pipeline\n# cp -r /content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/evaluation-pipeline /content/\ncd evaluation-pipeline/\npip install -e \".[colab]\"\n# Install other necessary packages\npip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n\n# Unpack dataset\n# unzip filter_data.zip\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "nP_CtLXNbz0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1433e6-1961-4d08-9799-ee3c71ab8000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.1.1 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "WoPl0Ubub1zD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecf46b4-2b1e-4b90-8b72-dad99cfb47cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Using cached datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "Ttj2qGrIb3ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7564f487-784e-44a7-84b8-829b077ea346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=931a1616bc9d324eba46149ff3e7da0ad240ced1254c620d89d248741b5d23e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lm_eval"
      ],
      "metadata": {
        "id": "9XAVOPX_b4xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f971a06d-e7e5-4875-d024-47d87a5b5dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lm_eval\n",
            "  Downloading lm_eval-0.4.8-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval) (1.6.0)\n",
            "Collecting evaluate (from lm_eval)\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval) (3.5.1)\n",
            "Collecting jsonlines (from lm_eval)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm_eval) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval) (0.15.2)\n",
            "Collecting pybind11>=2.6.2 (from lm_eval)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm_eval)\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from lm_eval) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval) (1.6.1)\n",
            "Collecting sqlitedict (from lm_eval)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm_eval) (2.6.0+cu124)\n",
            "Collecting tqdm-multiprocess (from lm_eval)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval) (4.51.3)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm_eval) (0.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from lm_eval) (0.3.8)\n",
            "Collecting word2number (from lm_eval)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm_eval) (10.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval) (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm_eval) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm_eval) (3.11.15)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval) (1.17.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval) (5.4.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->lm_eval)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm_eval) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm_eval) (0.21.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->lm_eval) (25.3.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval) (75.2.0)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval)\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval)\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval)\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval)\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval)\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval)\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval) (1.20.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->lm_eval) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval) (8.1.8)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm_eval) (2025.2)\n",
            "Downloading lm_eval-0.4.8-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Building wheels for collected packages: sqlitedict, word2number\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=1d9a1d4974fcfffa9c2634ae103e0b7e930ab85bf236190a5fa25d987033ccde\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=d0040353bcb9cb6ddee77ffaf8858f9dd13fd665a7cbdb8b78de4c82e395054d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, tqdm-multiprocess, tcolorpy, pybind11, pathvalidate, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, jsonlines, typepy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, DataProperty, tabledata, evaluate, pytablewriter, lm_eval\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed DataProperty-1.1.0 evaluate-0.4.3 jsonlines-4.0.0 lm_eval-0.4.8 mbstrdecoder-1.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pathvalidate-3.2.3 pybind11-2.13.6 pytablewriter-1.2.1 sqlitedict-2.1.0 tabledata-1.3.4 tcolorpy-0.1.7 tqdm-multiprocess-0.0.11 typepy-1.3.4 word2number-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load model and evaluate (BLiMP) { display-mode: \"form\" }\n",
        "model = \"/content/model_folder/\" #@param {\"type\": \"string\"}\n",
        "model_type = \"encoder\" #@param [\"decoder\", \"encoder\", \"encoder-decoder\"]\n",
        "# file_name = \"examples3.csv\" #@param {\"type\": \"string\"}\n",
        "# model_names = [\"opt-125m\", \"opt-350m\", \"opt-1.3b\", \"opt-2.7b\"] #@param {\"type\": \"raw\"}\n",
        "\n",
        "%cd /content/evaluation-pipeline\n",
        "%run /content/evaluation-pipeline/babylm_eval.py \\\n",
        "  \"$model\" \\\n",
        "  \"$model_type\" \\\n",
        "  -t \"blimp\""
      ],
      "metadata": {
        "id": "ZkLlbEO8b9SY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f3bc0d28957b4c08974ed286123f992b",
            "13a9ea26d40a45ecbb7a84647e5cd7f7",
            "73b9696b34934615931285a2e8777c46",
            "dea190db6a4844b0a217be284e7b5d65",
            "d5277b3cc5dc4cfc928f7593b17ec2ee",
            "48c97c147d0945f7bd09ed6aed6f1d59",
            "28b09bbee22b42959a016448fc768c1e",
            "a8b94b81e1b242a687debfac4dbb2e08",
            "f772e5c1c318430c94cc98319efc672b",
            "fd873019e91b450c9d0f72be14af7565",
            "8b867c3080d64f20853c77bb0b565532",
            "8b8e97ce4cb049b6987b9ac87591688d",
            "a7eba35fdf964c7e9360ef1bde97afd6",
            "201252f15a39498884418fc69c565626",
            "3613c951fe274cd386733e2e4c89116b",
            "705130fadbfe4f11bda37547b4d77581",
            "9d0d4604c6dd4b018d48b994637e4142",
            "204aea02c5174e6395f5fbbf5dfcef13",
            "a1dd32919182486faa632b4826f93b30",
            "70c1cf20215c470ea7cd2bf7ff8c00a4",
            "102e469127834e5fb8f2223410db00b5",
            "c3346b55322848f4a75ff613b42de7b2",
            "350fb95c8fe54f5792e9f77745161c53",
            "3fc6b92f43094f6bb27a3a27c32f4868",
            "aa800df78d0a4be090b576752667c62f",
            "536c2ded8d9b480b80c427f36aa6fe28",
            "375784349c9e4be9a895477cc1b67ad7",
            "f7027765da434a2ab9e9ee3f3f6822f5",
            "7c2eb259ce554f4192a68dc43e44d8af",
            "548274ca6357405584bf38bce73ebad5",
            "1ac6419e6a094c2a80c7db42f793604f",
            "4f67a9df80ae405a8d8dfbf0a41a992b",
            "f311874f35f540f49db42b07b9b5893d",
            "7052815b98194c62b104c3b1ed2f8a0e",
            "b5db396fd95a4ab382aff3f52ba3c403",
            "d1ace3f0d05d47a28a15818f08e81c82",
            "d1fbd3e7fcf64b50b0c56dbe2e4b31be",
            "f01d98696d5d40689c8de6792b8cad3d",
            "f00aaacceb1f4a5cbc558e7fc8c9f4bb",
            "8f9726de8c6e402794680a4bf2fc3753",
            "373058ffcd5f499b9767d41a20e3ab16",
            "0658a0882a684d55bdae1d5e5f3cd7bb",
            "0b53109036494f1db19d9464177c460f",
            "ad30e8452b814d6099c8c906c7549c39",
            "0a4922b4b47e4a6fbeefe52dcb434bfe",
            "80b7520927b544e9950deb4e08627cc5",
            "6d671461abfd4d268042c099e6c980a1",
            "e360017a91cc47b4b31697be5c937510",
            "e89101a2438d43a0b8930c04be3a3b32",
            "417e4fc53e4d4ad98409917ccb46234d",
            "a12775c254734911844b005a5c19108b",
            "fd6bf9b778024c9691f71fda3da19721",
            "a38d3cbd7d4b4877a6fbcc28352a9ebd",
            "0dbc1f1cbf6e452fa904cf93ff0b2499",
            "43130c055d4b4788b69a714e8b9d163c",
            "17e589fb77e2479598dccbd21b8071f6",
            "19283cdbd9b240788d5d847691a53663",
            "b1cb467d9947469798996f410fbcf122",
            "0034ec1b22474143b7fb1870f0afca10",
            "04b00fe8cc0a4aba969c2ec1aedd6861",
            "ca9ac146dcf94b4fa75604fa4a3c0a28",
            "a3fbc515d36441ad842a49072df93e78",
            "cb62b6e2b649491c93134feb6782416c",
            "e52d24fa84f74631b8c06b4e491831ba",
            "305b4d0618464615b6a9d0ec6d8e4310",
            "dea7ba967e4142a9bfe293608e20a4a9",
            "25219719faa4422ab396f194b4fcfbb9",
            "aeddd0aa5e10423e808b2afa41f30899",
            "f6cb8f874ac64029a21ece0b6e88d56c",
            "316e8e18216b4063beb8aebfcdc8e2ea",
            "d14e1729c9a743a6b8dd152412df8979",
            "8cb19df65ecd4e259fcd8bd9d14590ec",
            "50db13e0583d450ca0d338e94f21f454",
            "d96a39ea5c9a489aa1acacd3fca7972b",
            "c7b7c76c176f400cb10adc5618875c42",
            "71b09d962a0a4de58b09a78a4105c442",
            "19e4eb0c8e534d30a071fd2104854902",
            "0f71cedae75d4f13ace5c71ca5dc5547",
            "401c24fcdbac42a1b8cd95544480b69a",
            "5390fb0027a94fbdb687388b426a4ba5",
            "4d5a56a7d87a4b75966a1dbd4e404b3f",
            "2a04d503f23b4836b071da3fa4180022",
            "b7b9218aab984fd0b005488f7b272339",
            "75d59c2f783e47f1a994dd31caf24189",
            "b71e3619f91b4d9496cf4f6fb7f86148",
            "3be9ffb618064befa1eb4b96254203a6",
            "8e64a4ece1b84b20a32b42e5e3201962",
            "6633efa9adb2406284dc6f945df60120",
            "5615bee424fa4b69adc7ed28adf6311b",
            "6907c8d689f845c9a96cdd2a30b2b6bb",
            "37e3411174e148f4b8cb3b4aa5d2e4fe",
            "a42d7e9e408440da9c2762df24ec9995",
            "f276210339ec4c4784f584ee09e09d7b",
            "7c26e921e63841cbbd9d5b1d557c8b98",
            "79a9245abb884d96ab1f49878db0820b",
            "a0599e684e0d491d918108b251de6ac8",
            "6614add13d374937a109848ee5338f3c",
            "abda4849e41540348fc857581378098b",
            "94267d0630354e5eb0d0c67c1c12b23f",
            "2ddf4023b7ac4be98fb6960d28f436dd",
            "687973b9217c4fc1a95a31598486be55",
            "13d32ad3a715468bbd04b384bf606d50",
            "d119343f881140c5b83ae98c1475fb7b",
            "570afbf2184c47f490ca3906a788b9a0",
            "c7391e3ca1df49e894530e16261653ba",
            "24c09c5366ee4aab8363248257713c27",
            "39cae760e11f4335aa0d3b50feb685e8",
            "a14f3213125b45d1a7153a0cbf087aed",
            "c078e75923c843d0a83fbde51e0459dc",
            "1234b353918548febce6582f2c867381",
            "57f02bd75432405b996a0249560b3f66",
            "1634bed9487e411790cef40f1e3676e9",
            "12a7f6fac4bd48388c3bf28732eae797",
            "db9f5235e496439b9a4ac958fc9006b2",
            "2713ebff7f4c4a10a9217ec5e120f0ae",
            "0bd6ee367dc2498d90f1ef1f8fda89d3",
            "0f3015d5a1dd4454a5621ff43dbef357",
            "9d2b7e6c628a48879bf9620d1fb77a3c",
            "c7ff25e4d4594c7d8a97f65405c6a0c4",
            "7004fa9fd5b3460b96bd12c907106d8f",
            "9e6589b2bbdf453d8d6deee0285af869",
            "432f5ccb5f544f579526a92ec1f9daf6",
            "1f88de83dce24d13b8f76793485ded0e",
            "33932d4de5794a43acc4490ba62922c9",
            "826cd441fab14d2590e9e47710513d50",
            "33eb1fde9c32460492aa4511bccb0485",
            "80f8343890ca47d8bbea2738ffc7ec2e",
            "802981601e284ae3843eaa6c3ee4d37c",
            "e892aa1e0cee480fbcb20c6424c76b50",
            "1c87284e6e5f4bd9a243ca57424f2e3b",
            "ddfa470883604b52a96e2a6dd7fd0c1e",
            "76cef2eedbb742bbb4081fb3dc8ff434",
            "17a6d7c13fc647bc994aa5e77d69a44c",
            "367c2a23696946798d809e8af238098e",
            "10075857c8064c90af77f553db098b71",
            "954cea94f04d42dfb7229f151896f472",
            "9dd6e08c002e448f86ca7b35c45ed181",
            "a8d1e2cca0474d3cbe83bb02bb843595",
            "ed2ab800f4134d1792c856c72f9a37f2",
            "96ea0fe29b074489aaecb586dfaaaba6",
            "c17f801e42e8442fb44cb9bf06c22333",
            "980e33e62c8d45819918bf8e6569f426",
            "c547de4291b24a60bfb5ede10fcc7f3a",
            "9081c23c419d43e3a5c9561d2816dc41",
            "b9068ec60edd43e293cbe3fd4229c9a3",
            "573c9db5b9d74ea4baeb0749482c6505",
            "1a420676c7fb4175a39e960bd05cc7f2",
            "2fd152f4ba0b4651bbd2063c30eef20e",
            "af1d8fb3dee34921ad8e42ff31582757",
            "fc59b860db0a454e92d1aa677f364887",
            "27aa86c900cb4669bdab05127a3911be",
            "ff3c2639c0c348ceb4d800ec3c9abe91",
            "e5b305b6e10c45dea763daacd8927648",
            "177901ac7eff4c3d8006fab07b99471f",
            "22c8419c5ff54fd2bb3fb15b3dfccc80",
            "30254509ca9048b1ac4fc8972a465c67",
            "66f19e72b5b94e2787242606c769dfc3",
            "7d845230ab054e60b386e501c4bce618",
            "36ab7533361c476c96edafbe37e91a59",
            "48f85527dd554aaeaa5034fb8e4c3ec3",
            "af60b2f779a340cf861e033857fd132f",
            "b2f96ad8ce4545e48236615ec03474bb",
            "20e0661a35b44a3bad28b7b332689a8a",
            "9894c78724644de98e524f234b20e72a",
            "c87d90c8da434f9d80b8760ed3f241a4",
            "6ba44e45239a49228e6b8846dd68c3c7",
            "d511758896ee48e2a2ed38cb29b7206f",
            "18b1f3370a9b45bfa32875441f7de9fc",
            "9ea313fc26ae4150bb9f01d98a9c96d3",
            "0118f89185d8454a966208ae6ed4f06b",
            "08078334d90a4a03875ba92a63d459af",
            "fa688841d18c4dcabf0e9d211cc4723d",
            "bc715ae829914348ad8f65aa1f9e5ceb",
            "c49479ebd43b49668008bb9214da235f",
            "02bf14f1edca405da099c4fb2d538331",
            "c4a436ff1a9542078e2066660722ef96",
            "e9ef9a0d549347838714d7f544e8098e",
            "c0235bd6592a4cfb8ba4a456102ea298",
            "1db89985257a4dc8af8cd0af8960ddc8",
            "f002794dcc0c447d90a2fe9266b7aed1",
            "b04c797478df4235a021bc3efb3c2a59",
            "ff20367fd6a04f14a76a6506dc36cb23",
            "cdf3ac81bac74236b8217c178ea43fee",
            "992c14915c364ca7bba680a8b6ad517c",
            "6411ecaaaeb942a59d2d8f6a65581a91",
            "60a894794e2c47f8b8ce760d64868184",
            "2a08b0100cba40a5966c14bf54345c05",
            "5950dac717db4960b91c8768d30f6510",
            "3e22cc781cd841a085e89ea7e8bd1853",
            "c4352666c604405b995d568a2cf99046",
            "a0d2c24c831f4e2480a314d11e963365",
            "40b19a5ea8124c81a9891c03846798e2",
            "6e04ee78d0b54852be6599dc466a3b98",
            "fc3ae5dcf7a04d3a885392889279c1bb",
            "609d7d19a0d440389c22b0cde2a11bfe",
            "38640ce9f79f4c3096e2cd860146d893",
            "ba289437a0cb47d0a8609b553ebe7eb4",
            "c887cdfc11b64601bc2fc472131a8797",
            "ce33746138524aafbd3d166777d5338b",
            "b42948aba5ae4d67ab39ccf86f659dd1",
            "2f6357e85b664d549c7e07901dd85366",
            "04862f3c135e40c882ec04d2928a4fcb",
            "56a17cf9ed1e42899ad339c4551459d0",
            "b08d55c76b8943f4a203df29fbf294ec",
            "76634921204b4ec2a3f82e8609aca13c",
            "bd2ff01f424042cb9ff369a681b2329c",
            "02638f5b7c064e52bfab610c66ac999f",
            "270e225fffab49adb1385ca5736f4438",
            "6d99abbb8e2e4200829122e0d672b42c",
            "e9de141f727b4f2491afb4455d72f77c",
            "1a7f4e71f37e47e98ad5989dc0151fab",
            "ca3a7ef00e1d47a18ed77fb7ba941d21",
            "f9850bf4aa5945769fd87a333fe8a983",
            "9e875ff1d0fd421795212a4ce559ddfc",
            "eb6272777c394abbbdc0f8e9b101f0a8",
            "8ac75a91bb204f79bfb33dc5cc3d2e53",
            "3ef71aa429304e40a098dc997c016c9d",
            "2326e3bad93a4c36b008c47759191a6b",
            "91d8fa0016484d70b348951468311e47",
            "229e18ee2fd94653ab47d407406cb0e7",
            "503d6f249e444dda83a6c6888c843ba1",
            "d1ffcbf66c6841fba85ee74ab444eaa3",
            "1ccdd66eb4b34bac9120dc5b8653e881",
            "3303e6e04d124437b9c398e796c54773",
            "ef05e787e4de44749be6b9d2263bf023",
            "c96ea6d850b04cb99bbadb3be6c357c4",
            "bdd5f5e43f784408bf0d05903142947e",
            "6aea712d1c6145c8ad1b13bdee3b73de",
            "ddbe264623744e1c8f011d46d93d235b",
            "bc8408f452af406692bd9a0aad3cf42e",
            "cdff6bca833044bbacc732e3310f5e93",
            "6de16a269c02423b98aee31d4040057e",
            "9ce03125550f404182045108b023245f",
            "b497d71e3abd4ceb8696818bf9954be9",
            "0ce345b48bfa45bb8cf8b4dc6ffdaf0e",
            "dfda1075b7fc4f6d865eb4ed06ef5707",
            "56283d4879e246a49241ef0c39b10ae7",
            "53069b604e80478b9bd96cbd712b1703",
            "0661a99ac52f48688ee5b3e4b9bf5f88",
            "490d09db36c647a99cf1cd3cd69a51f9",
            "a80e795652994d22982cb365c3f4b4c4",
            "ea2665caa8fb4edc91ddb7bee8af2bbe",
            "9f5096b3dd8540b2962f77e01ece5c0e",
            "9eee5e7bbff94ef3be5d2dbf011c8630",
            "7bd44f90997a4711b343f2067382358d",
            "3c5a0242a98e46518674b746d8f4c96c",
            "1667c4c98c5e4d248ad7442d11a155a6",
            "8180ef252ea34a189c0a20589c887615",
            "2af652c5744740348a42b1ad48fa2a06",
            "301d08c96a9f44dcaabd82691c70abfb",
            "a776afd44b644dd7acc4ff9e1ee3028c",
            "078e25ce24654f599d56d0e290d22899",
            "e6479b28f4754c5698b4fe9045b066ec",
            "4cafa4b1ccb647c69f9528895060922b",
            "281f31344f65411eb9e46d1c0a5dac0f",
            "9b029482ba4140ce9833a5bbddbc37fe",
            "5fc36bbc92a04fa0b3c68a308c8fef5d",
            "878a131ffd5d46648f799ef4ddabf5b7",
            "6d4e61f112354b48b4b6f78aa6b26784",
            "8fd2f32370a249388a9c025e67a75aaf",
            "73113c271e1e47adb9aad65efaa9ce96",
            "498038df8f8d4bdaaf052fb2e12abc1c",
            "d61492d101fb48b3ab254e54ec5627b7",
            "fdbd9237fe5c43f6892419aae872c5b4",
            "72ab8d6f6fb04e04b5bd3c6c1a0446a8",
            "10b4e99e8f944e59b8b7d40977b6104f",
            "47ce21a71623492a9c669f25cf0e4903",
            "f1d830eb663a4bb5a8ab7a099a2fe063",
            "f87bb3bf9aa547488ec5add70c51fdd9",
            "c324851941514ba8afcbbcacd533e822",
            "72f5cddf13b04a0d848eeac868ec1443",
            "9838e1c779f648a0a2256aedd0b249bc",
            "4911f5d185a648669c4488a612872752",
            "e7d4f3e93266454faa6a2c5a086e07a4",
            "a45fa70951e84ed0b596d5178c7e565f",
            "cda641e421784ce59ee1d51cc8cbb6a6",
            "26a1a0aa5ed94d3f9ea7b28c695a0f05",
            "77648a53126a471fb2c3a77403b241ff",
            "cddc859e3df2452da7840c644d876dac",
            "fabb8aed9a0348aba15837f952261fd6",
            "cc4e12fdfbb144a488d06a09bf93e988",
            "02a0f14514ec4f39bbe4e6e47c8543d1",
            "a4241cb80e814b57b48f8f0b29895255",
            "7b49c5b68e7548a3a94a12a529f15049",
            "6ca141d81a254c44b4c6a80ad48eda86",
            "4e619879cc884ac5b9f1dd38ba5be9a1",
            "ddfef6931db24a9db90de7719ef45593",
            "260eccfbd17b4946bd54f3a4d758f622",
            "1a7571a978a143d5964a099481a0e789",
            "e3539b99e5554160b318d310ffaeaa6a",
            "3ac2c697080443cfb9d2065315743836",
            "1974d89446c347f394de82291f9857ff",
            "ca906108f2fc481986cb601c3bdfed7f",
            "5a7ecb69505f4cf2b8c92c4fca1ef1be",
            "463d7f68cc5f443ea20350c1d98bbb92",
            "36cd01b7f0034bbdbb5b21e569e5d334",
            "2d83776dfae24e839a7997d6ae4d79a5",
            "c81df4272073468caf48fceae82297b3",
            "fbaf16518188461881bb672c9d44b31c",
            "322e2c6287a84470b34cf8626f8982e6",
            "61f0436563044a9388f2e805df5a3681",
            "708de031fd1f4e88be62ff613a081169",
            "06960cfc4b0441689cf50566327ab64b",
            "fd29cdef9d0f4c6da614e7d8d58b9e9c",
            "77e63a9ce855479682a55278a6953ac8",
            "37c481b742b0495d89a128dbd547c521",
            "5ceea85725004e7ca255519a226cfdd9",
            "5fbd233acc00476a9b2f2916c34e69a9",
            "167369d5a7d24e66a27a5e6940e95c39",
            "15d784a88d99488b973fdfdc6869a8bb",
            "8dd7dcec2ac24b4dab60f30f041fd1fc",
            "b70feaf6af0e40329440ccaa86cc11aa",
            "4273ad1a8070450998331ad51190bc03",
            "8897ec8368564a97ad75a5e130481374",
            "ce9e442f8c784d0a8e4d26fc6c42ff99",
            "679035798209433282c1ce1ce12d49ac",
            "820fd73d40414c3fbe2e2d1358b29377",
            "58b9552166f348e3ad8364bf8be8d719",
            "70373f8d71b84c8aaae4be6413102603",
            "9b5ddf4162ec4748865971403b55c569",
            "8a64dc0552aa4002b305fc72fc751f38",
            "c2ebc67fb84c4a2c8c9f70c601d3ead7",
            "39641d3a34b74caca2f0f46d36dad433",
            "f7c5a690c46e4342bea1b204043fbac4",
            "9eb15cd4c9b34c068cc642dad8da8729",
            "720b2dbdc6b34ba996721e99cb4588df",
            "222bea1aad9f4ebb83eeaec4aa499a0e",
            "45d52943c96e4c71bfe5ab4d4bf627b5",
            "87145ef10dd74112845e4d8f94cdb702",
            "8f0f8afc42244682bd2b50b36f727e25",
            "773c60650dfb4e4282e1702bcb5b9142",
            "d72f8c309b844173942790fc3dcd0f07",
            "8778cd817b0b4ce1b0e3a941c3702dd0",
            "3bf97262f24a443597af65a2ed66c147",
            "e484bcdebc96416b84021b06576f8748",
            "eb3a5340413b4f37a1a5c656cc93164c",
            "adbda9a717d843b6a860162f751928cb",
            "64edcb1d7e95417f8fc709822c136bd4",
            "a896c2e8010d4e3a9cd0c26d7a684d6f",
            "b58ad195d15d4b5fa9eff43ec4e70937",
            "9fa6633e5bfc4ede9195b914da746955",
            "2dc5fa634e8d431aa4c3477419dc826f",
            "07d91e2411a541de9c1b7ed7cf22cafd",
            "c3f7e99407d84d62bcf7731d6b9d1425",
            "0bb26d2f0d7545caa1c0cfe8af8b9ecc",
            "ebcd0422ae0446b88d571e15db57693e",
            "55d214ade3394514b84e4c7b6453d29d",
            "d768389bb3e84eedbb16b154ba8b37d0",
            "d599179217c64a74ae93fbc5d9f00f2c",
            "aabdb13037654eea86efbe1f7ef57c66",
            "4ccd85186c2b4d3784ca4ca131d5a089",
            "a86c54d6680a482f9bcb2a08d21cb30f",
            "fec8d22efad94556b42073fbb93b7202",
            "fde0a3e3a37e4f2586dad401b81ef039",
            "e7b57522d2ec4bec9d044d8167175261",
            "1170530959bb422bbc6fc5f6d4db945c",
            "d9d48586ad2e4f24a293013ede72e641",
            "cf00913b7dc94f92ba774d5866f7a99e",
            "302e182ab5e643a9a50152df474efd51",
            "c606be853c374e6ebcae0f51c5f682bc",
            "12a91a7a1be64f41b8c4c1270beeca1b",
            "6e8cf690752f40998a69e2aaad54d3b4",
            "3503deaca4b549d5ac684a8ac1a469bf",
            "5768511103ae4033ba6e0412ac3d901e",
            "fa4b6e174c1b456ab5b0e2d66751b5c8",
            "c0b8413e77714c68946f69fd1465dd69",
            "d184f20e7a534edfbd2c68bc3e3dfc70",
            "5ad3380b373a4719a2927c87d7cb40d2",
            "9310c659ceed4b5db0beaefe508da433",
            "bc87a28553b44b90aea33449730e7d8d",
            "ad9d5e643abe4d1a95cfa5d593868023",
            "d081f890d8704e758f1b662ba36a7962",
            "71e61e20cc1b439a92acab4b8201a48d",
            "ecdeb64ed0954ce696b1a5fc45b9b964",
            "098109859bcc4daf91396ba7c63fc5a3",
            "0c0e35350d2649d398a9674fb315dc6d",
            "169012ebb2034d35a89c7be820d40498",
            "f9ca46b71b8941ffb01b7434448218e1",
            "701a7df61bbf4ceb92548ed8902642f7",
            "74301051a11b451a97b5071caab1ed34",
            "4dd14c5415fd4922863cf99842a98c64",
            "4c45324d55c04d0ca43c06f3f564af14",
            "0907bba9e92746558ee1b6319624c8b6",
            "2c978517627d4b5a8e981a8c44143731",
            "72e8e6de3d26466fa5de84a8e6cf9f57",
            "9c9711b178c641d1a7ee596f433a1ea7",
            "d8b6ae8f85d74c49a6ae2dfd0250bb11",
            "7f8732bc7b514d9eb2adb1cf88194a60",
            "b2196ea85211469f9f8081c6e11f9e04",
            "64e516b7851d4ad893c9f844cd376e4b",
            "292f55c4121046269067c92d8f586683",
            "83c07b25c5a94280a7530abe39255037",
            "c483d59a4f1f4c96b1f412948627d7b3",
            "96f59c3a554d475891aff62dd98bf4c3",
            "ba452e6e858c48fca28da9aa6298be3f",
            "6839f9a17dd54165a097ba0382650977"
          ]
        },
        "outputId": "fce8fcfb-689b-439d-c975-b7fe37757e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/evaluation-pipeline\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3bc0d28957b4c08974ed286123f992b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1956 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b8e97ce4cb049b6987b9ac87591688d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1956 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "350fb95c8fe54f5792e9f77745161c53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 1956/1956 [00:00<00:00, 7191.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 3912/3912 [00:23<00:00, 168.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anaphor_agreement:\t62.68%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7052815b98194c62b104c3b1ed2f8a0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8248 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a4922b4b47e4a6fbeefe52dcb434bfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/8248 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17e589fb77e2479598dccbd21b8071f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 8248/8248 [00:01<00:00, 7049.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 16496/16496 [01:37<00:00, 168.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "argument_structure:\t61.92%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25219719faa4422ab396f194b4fcfbb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6738 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f71cedae75d4f13ace5c71ca5dc5547"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/6738 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5615bee424fa4b69adc7ed28adf6311b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 6738/6738 [00:00<00:00, 7210.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 13476/13476 [01:23<00:00, 161.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binding:\t63.24%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ddf4023b7ac4be98fb6960d28f436dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4526 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57f02bd75432405b996a0249560b3f66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/4526 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "432f5ccb5f544f579526a92ec1f9daf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 4526/4526 [00:00<00:00, 4623.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 9052/9052 [00:58<00:00, 153.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "control_raising:\t61.07%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17a6d7c13fc647bc994aa5e77d69a44c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7542 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9081c23c419d43e3a5c9561d2816dc41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/7542 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22c8419c5ff54fd2bb3fb15b3dfccc80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 7542/7542 [00:01<00:00, 7179.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 15084/15084 [01:29<00:00, 169.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "determiner_noun_agreement:\t74.09%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ba44e45239a49228e6b8846dd68c3c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1732 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9ef9a0d549347838714d7f544e8098e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1732 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5950dac717db4960b91c8768d30f6510"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 1732/1732 [00:00<00:00, 7179.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 3464/3464 [00:25<00:00, 134.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ellipsis:\t45.50%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce33746138524aafbd3d166777d5338b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6426 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9de141f727b4f2491afb4455d72f77c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/6426 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "503d6f249e444dda83a6c6888c843ba1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 6426/6426 [00:00<00:00, 7246.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 12852/12852 [01:24<00:00, 151.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filler_gap:\t62.76%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6de16a269c02423b98aee31d4040057e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1965 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f5096b3dd8540b2962f77e01ece5c0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1965 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cafa4b1ccb647c69f9528895060922b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 1965/1965 [00:00<00:00, 7147.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 3930/3930 [00:22<00:00, 178.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "irregular_forms:\t69.97%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72ab8d6f6fb04e04b5bd3c6c1a0446a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2676 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cda641e421784ce59ee1d51cc8cbb6a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/2676 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddfef6931db24a9db90de7719ef45593"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 2676/2676 [00:00<00:00, 4428.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 5352/5352 [00:33<00:00, 158.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "island_effects:\t39.57%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c81df4272073468caf48fceae82297b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6586 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "167369d5a7d24e66a27a5e6940e95c39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/6586 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b5ddf4162ec4748865971403b55c569"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 6586/6586 [00:00<00:00, 7402.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 13172/13172 [01:20<00:00, 164.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "npi_licensing:\t53.81%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "773c60650dfb4e4282e1702bcb5b9142"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3882 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dc5fa634e8d431aa4c3477419dc826f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/3882 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fec8d22efad94556b42073fbb93b7202"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 3882/3882 [00:00<00:00, 4194.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 7764/7764 [00:47<00:00, 163.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quantifiers:\t62.73%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5768511103ae4033ba6e0412ac3d901e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Assigning unique IDs to 'blimp_from_file+null' docs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5535 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "098109859bcc4daf91396ba7c63fc5a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Filtering invalid docs from 'blimp_from_file+null'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/5535 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c9711b178c641d1a7ee596f433a1ea7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lm_eval.evaluator:\n",
            "» Constructing 'blimp_from_file+null' contexts and requests\n",
            "100%|██████████| 5535/5535 [00:01<00:00, 4976.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "» Running all `loglikelihood` requests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lm_eval.evaluator:\n",
            "» Running all `loglikelihood` requests\n",
            "100%|██████████| 11070/11070 [01:06<00:00, 166.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subject_verb_agreement:\t54.47%\n",
            "\n",
            "Scores:\n",
            "anaphor_agreement:\t62.68%\n",
            "argument_structure:\t61.92%\n",
            "binding:\t63.24%\n",
            "control_raising:\t61.07%\n",
            "determiner_noun_agreement:\t74.09%\n",
            "ellipsis:\t45.50%\n",
            "filler_gap:\t62.76%\n",
            "irregular_forms:\t69.97%\n",
            "island_effects:\t39.57%\n",
            "npi_licensing:\t53.81%\n",
            "quantifiers:\t62.73%\n",
            "subject_verb_agreement:\t54.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/model_folder/zeroshot\" \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e5_v40_l4\""
      ],
      "metadata": {
        "id": "QUY6rGfRdHth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLiMP Evaluation for Epoch 10"
      ],
      "metadata": {
        "id": "K4K9n93EGR2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/evaluation-pipeline\" \"/content/\""
      ],
      "metadata": {
        "id": "4U91WRE-GR2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/lm_eval\" \"/content/\""
      ],
      "metadata": {
        "id": "_M3FeKONGR2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model_folder\n",
        "\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4/config.json\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4/merges.txt\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4/model.safetensors\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4/special_tokens_map.json\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4/tokenizer.json\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4/tokenizer_config.json\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4/training_args.bin\" \"/content/model_folder\"\n",
        "!cp \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4/vocab.json\" \"/content/model_folder\""
      ],
      "metadata": {
        "id": "i230rxvUGR2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup script { display-mode: \"form\" }\n",
        "#@markdown Run this cell to install the necessary packages (may take a few minutes).\n",
        "%%shell\n",
        "# Remove previous installation if it exists\n",
        "cd /content\n",
        "# mkdir model_folder\n",
        "pip uninstall -y lm-eval\n",
        "# rm -rf evaluation-pipeline/\n",
        "\n",
        "# Install evaluation-pipeline\n",
        "# cp -r /content/drive/MyDrive/VU Thesis/Code/BliMP_eval_code/evaluation-pipeline /content/\n",
        "cd evaluation-pipeline/\n",
        "pip install -e \".[colab]\"\n",
        "# Install other necessary packages\n",
        "pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "# Unpack dataset\n",
        "# unzip filter_data.zip"
      ],
      "metadata": {
        "id": "dcxirSJ6GR2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "U07o7qSoGR2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "vXmdbm1sGR2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "_D9zv8xdGR2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lm_eval"
      ],
      "metadata": {
        "id": "y0ieslOEGR2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load model and evaluate (BLiMP) { display-mode: \"form\" }\n",
        "model = \"/content/model_folder/\" #@param {\"type\": \"string\"}\n",
        "model_type = \"encoder\" #@param [\"decoder\", \"encoder\", \"encoder-decoder\"]\n",
        "# file_name = \"examples3.csv\" #@param {\"type\": \"string\"}\n",
        "# model_names = [\"opt-125m\", \"opt-350m\", \"opt-1.3b\", \"opt-2.7b\"] #@param {\"type\": \"raw\"}\n",
        "\n",
        "%cd /content/evaluation-pipeline\n",
        "%run /content/evaluation-pipeline/babylm_eval.py \\\n",
        "  \"$model\" \\\n",
        "  \"$model_type\" \\\n",
        "  -t \"blimp\""
      ],
      "metadata": {
        "id": "6N7YwpaoGR2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/model_folder/zeroshot\" \"/content/drive/MyDrive/VU Thesis/Code/seeds_experiment/V40L4/seed_1278/model_s1278_e10_v40_l4\""
      ],
      "metadata": {
        "id": "rcKalHSzGR2o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}